[{"content":"It is very important that data is accessible and reusable for society and industry. Nowadays, it is crucial that data has the capacity to be accessible and reusable not only for the workforce but also for regular users, such as someone using social media and trying to download their own information.\nCreating, saving, ingesting, transforming, processing, and visualizing data are tasks that require time and effort. Additionally, maintaining security, executing administration, performing operations, detailing orchestration, preserving good software engineering practices, and defining data architecture strategy are extremely critical aspects of the data ecosystem.\nOf all these points I mentioned, I want to focus on what data architecture is. There are several data roles in the workforce that sometimes become overwhelming or even a bit difficult to distinguish from one role to another.\nIf you\u0026rsquo;re familiar with data roles or rather if you have experience working with data, you\u0026rsquo;ll agree that sometimes a Data Analyst does the work of a Data Engineer, or vice versa. Likewise, a Data Scientist may be working for a company solely doing SQL queries and dashboards. I could continue with countless examples, but to not go into too much detail, this practically depends on the data maturity of the company, organization, or project.\nWhat is a Data Architect? If you search on the internet, in books, or consult someone with experience in data, you may come across different definitions of what a data architect is.\nAccording to the book \u0026ldquo;Deciphering Data Architectures\u0026rdquo; by James Serra:\nThey are the ones who design the high-level structure of the data architecture (MDW, data fabric, or data lakehouse) and decide which data governance technologies and policies the project should use.\nAccording to TOGAF:\nThey are responsible for describing the structure and interaction of the main types and sources of data, logical data assets, physical data assets, and data management resources of the enterprise.\nAccording to DAMA DMBOK:\nThey are the ones who identify the data needs of the company (regardless of structure) and design and maintain master plans to guide data integration, control data assets, and align data investments with business strategy.\nAccording to the book \u0026ldquo;Fundamentals of Data Engineering\u0026rdquo; written by Joe Ries \u0026amp; Matt Housley:\nThey function as a level of abstraction from data engineers. Data architects design the model for organizational data management, mapping processes and overall data architecture and systems. They also serve as a bridge between the technical and non-technical aspects of an organization.\nThey also have another definition:\nIt is the one who designs systems to support a company\u0026rsquo;s changing data needs, achieved through flexible and reversible decisions reached through careful evaluation of trade-offs.\nNow, which definition to choose?\nSummarizing all these definitions, I could do it like this:\nThey design the overall structure of how data is stored, organized, and utilized. They decide which technologies will be used to manage the data They create rules and policies to ensure that data is of high quality and reliable. They ensure that data systems are flexible and can adapt to the changing needs of the company. They are like data engineers (practically functioning as a level of abstraction), who design the necessary systems for the entire data lifecycle so that companies can make the most of their data.\nA data architect analyzes the pros and cons, designs with agility, and adds value to the business.\nAnd what is NOT a Data Architect? Everything involving both strategy and tactics can be considered as Data Architecture.\nStrategy involves the questions of what, why, and when, while tactics involve the how. Let\u0026rsquo;s suppose someone from your company comes to you and says they need to integrate information from various sources because they want to leverage the data. As a data architect, you have to start investigating what exactly they are dealing with, you have to know why they want that integration and data leveraging, and you have to know when they need this type of solution.\nIt\u0026rsquo;s not that these are the only questions asked by a data architect, but what I want you to understand is that it\u0026rsquo;s not correct to say, \u0026ldquo;We have X, Y, and Z tools to extract and analyze data\u0026rdquo; because that brings negative consequences to the solution design.\nBesides strategy and tactics, data architects must be aware of three main aspects when embarking on a new data architecture design:\nCompleteness Accuracy Consistency Most of the time, the stakeholders don\u0026rsquo;t know what exactly they are dealing with, so it\u0026rsquo;s crucial to be present when making those functional requirements. It\u0026rsquo;s an art in my humble opinion; if you\u0026rsquo;re lucky, they just know that they need to integrate and leverage data. (Believe me, sometimes that\u0026rsquo;s a really good starting point)\nBut these tasks are made by a Data Engineer, right? It\u0026rsquo;s true that a data engineer can do all of this, but as mentioned earlier, data architects function as a level of abstraction. Furthermore, I\u0026rsquo;m not an expert in buildings or houses or apartments, but I know that a civil engineer could do the work of an architect. So why do architects exist? Because they focus on strategy and tactics, while engineers turn what is designed into reality.\nA Data Engineer is responsible for creating, testing, and maintaining data architecture. They write the corresponding scripts to extract, load, and transform data from one or more sources and turn it into a data solution, working closely with a data architect to implement the designed architecture.\nWhile an engineer can do architecture work, it\u0026rsquo;s important to establish the limits, objectives, tasks, and scope of what they can do. I say this because you have probably encountered job positions or employees in your workplace where an engineer does more tasks than they should.\nNow tell me, of all these roles that exist, which ones have you seen end up being \u0026ldquo;combinined\u0026rdquo;?\nData Analyst Data Scientist Business Analyst Data Engineer Database Administrator Data Steward Data Architect Data Governance Manager Data Quality Manager Project Manager/Scrum Master DevOps Engineer Product Owner/Manager What I can tell you is that it\u0026rsquo;s \u0026ldquo;normal\u0026rdquo; for this to happen, but it\u0026rsquo;s crucial to keep in mind that there is the possibility for one data role to encompass several data roles.\nTheir Role in the Data Engineering Lifecycle It\u0026rsquo;s important to understand the data engineering lifecycle due to its impact in every step of a project. (Basically, bring business value to stakeholders)\nGeneration Storage Ingestion Transformation Visualization or delivery Data holds value at every phase of this cycle, and data that isn\u0026rsquo;t consumed or consulted can pose a risk to any company. Many companies, simply by wanting to undertake ambitious projects in this era of big data, ended up (and continue to) collecting massive amounts of data that ultimately weren\u0026rsquo;t used correctly.\nProjects must have intention throughout the entire lifecycle, both in engineering and in data. A data engineer will be responsible for extracting information in a timely manner, following correct security and integration protocols, and whatever else you want to add.\nBut does a data engineer\u0026rsquo;s job end here? That\u0026rsquo;s what I want you to understand: A data architect has to evaluate, design, organize, and see the value in the phases of the project. A data engineer might do all of these tasks, but it\u0026rsquo;s not their main job.\nFor instance, let\u0026rsquo;s think that you go a hospital and meet a doctor. Probably you know for sure the doctor will:\nExamine your condition Make a diagnosis Prescribe medications And surely wouldn\u0026rsquo;t do:\nClean the hospital Make the medicine Manage hospital administration But what about data engineers? Expectations are unclear? They can or can\u0026rsquo;t do:\nDesign the data warehouse data model Handling application databases Creating a data pipeline for machine learning Handling all big data infrastructures and software installation Analyzing big data to transform raw data into meaningful insights As I mentioned before, if companies were more data mature, then there\u0026rsquo;ll be better well-defined boundaries. In the end of the day it also depends of how the modern data managament tools rise with the increasing complexity of the data.\nSo what should a Data Engineer do? I think there is a distribution of knowledge from an end-to-end data lifecycle, and that must clarify what skills/knowledge are a \u0026ldquo;must\u0026rdquo;, what are \u0026ldquo;good-to-have\u0026rdquo;, and what are \u0026ldquo;nice-to-have\u0026rdquo;.\nHowever, a \u0026ldquo;must\u0026rdquo; in one company is a \u0026ldquo;nice-to-have\u0026rdquo; in another. It really depends on how the company and its customers operate.\nCommon Challenges in the Data Realm Not only as a Data Architect, but also being as one related role mentioned above you\u0026rsquo;ll encounter common challenges in the data realm.\nIf data maturity is low, you might encounter:\nData Silos Limited data literacy Inadequate infrastructure Cultural resistance Security vulnerabilities Now, if you go to the other end where data maturity is high, you may encounter:\nData Governance and Management issues Innovation with emerging technologies Development and maintenance of advanced analytics I mean, in both ends you might find a little bit of everything, but it\u0026rsquo;s important to keep in mind that there is a lot of data that is not used correctly. When not used correctly, it might be because of a bad data architecture design, or a bad data governance or management, or bad data quality since creation.\nConclusion In summary, a Data Architect plays a pivotal role in shaping the data landscape of an organization. They are responsible for designing robust data architectures that ensure data is accessible, reliable, and secure.\nBy focusing on both strategic and tactical aspects, Data Architects bridge the gap between business needs and technical implementation. Their expertise in evaluating trade-offs and designing flexible systems is crucial for adapting to evolving data requirements.\nUltimately, Data Architects enable organizations to leverage their data assets effectively, driving business value and innovation.\nTL;DR A Data Architect designs the structure of data storage, organization, and utilization, ensuring data quality and flexibility. They focus on strategy and tactics, working closely with data engineers to implement the designed architecture. Understanding the data engineering lifecycle and common challenges is crucial for adding business value.\n","permalink":"https://thedatafixer.xyz/posts/why-being-a-data-architect/","summary":"It is very important that data is accessible and reusable for society and industry. Nowadays, it is crucial that data has the capacity to be accessible and reusable not only for the workforce but also for regular users, such as someone using social media and trying to download their own information.\nCreating, saving, ingesting, transforming, processing, and visualizing data are tasks that require time and effort. Additionally, maintaining security, executing administration, performing operations, detailing orchestration, preserving good software engineering practices, and defining data architecture strategy are extremely critical aspects of the data ecosystem.","title":"Why being a Data Architect?"},{"content":"I\u0026rsquo;m Omar Valdez.\nMy purpose is to share my knowledge with the community interested in the fascinating world of data, and my goal is to encompass the entire data lifecycle ecosystem, from generation to deployment. Additionally, I want to highlight the key elements that underlie the data lifecycle, such as security, data management, DataOps (data operations), data architecture, orchestration, and software engineering.\nWhat I will NOT talk about:\nI will not focus on general topics. You won\u0026rsquo;t find content like \u0026ldquo;5 truths about Python\u0026rdquo; or \u0026ldquo;A day in the life of a Data Engineer/Data Scientist.\u0026rdquo; I will not focus on news. Although trends and advances in the field of data can be discussed, the main objective is not to provide daily news or current events. I will not focus on pure theory. The goal is to provide practical and useful content, so I will avoid overly theoretical approaches without concrete examples or use cases. One of my main goals is to guide those who are already immersed in the world of data but wish to deepen their understanding, their influence, and above all, their potential.\nThrough tutorials, practical tips, personal reflections, and case studies, this place will be a valuable resource for all data enthusiasts, whether for a curious beginner or an expert seeking new perspectives.\nI\u0026rsquo;ve held many roles in the data universe: Data Analyst, Business Intelligence Analyst, Data Scientist, Data Engineer, and Data Architect. Practically, my experience with data has ranged from being on the front lines creating reports to designing architectures.\nData should empower, not intimidate, and I\u0026rsquo;m here to bridge that gap.\nAvatar Perhaps you\u0026rsquo;re wondering about my avatar. Basically, it\u0026rsquo;s a metaphorical representation of my approach to data:\nPixelated: Just as pixels are the building blocks of a digital image, raw data forms the foundation of our digital landscape. Technically, it\u0026rsquo;s unrefined, unprocessed information waiting to be transformed. Plumber: Similar to a plumber who works to repair and maintain a building\u0026rsquo;s plumbing systems, my mindset is to dive deep into data pipelines, unclog bottlenecks, and ensure the flow of data. Video game aesthetics: Similar to how games foster exploration, creativity, and problem-solving, I tackle data with a sense of curiosity and a desire to make it accessible and engaging for everyone. Avatar created at: https://demize.gg/TerrariaMaker/\nContact: info@thedatafixer.xyz\n","permalink":"https://thedatafixer.xyz/whoami/","summary":"I\u0026rsquo;m Omar Valdez.\nMy purpose is to share my knowledge with the community interested in the fascinating world of data, and my goal is to encompass the entire data lifecycle ecosystem, from generation to deployment. Additionally, I want to highlight the key elements that underlie the data lifecycle, such as security, data management, DataOps (data operations), data architecture, orchestration, and software engineering.\nWhat I will NOT talk about:\nI will not focus on general topics.","title":"[~] $ whoami"},{"content":"If you\u0026rsquo;ve ever felt overwhelmed by terms like Data Lake, metadata, or Data Governance, then you\u0026rsquo;ve come to the right place. I know that even for the same concept, there can be different interpretations, so my intention is not to define but to explain the word in a simple way, accompanied by an example or context.\nIf you think something should be added or edited, you can leave a comment at the end of this post, or you can also contact me in whichever way is most convenient for you.\nData They are facts, figures, or raw information that are collected and stored for subsequent analysis. It can include facts, numbers, measurements, observations, or any other detail that can be used to understand a particular subject.\nIf you are recording daily temperature in a city for a month, you can collect data on temperature, humidity, wind speed, and precipitation throughout the day. Data exists in various forms and can be found in everyday situations.\nMetadata It\u0026rsquo;s information that describes other data. It provides details about the content, quality, condition, origin, and other characteristics of a specific item. In the digital context, metadata can include details such as the author, creation date, file size, and keywords.\nIf you have photos on your smartphone, open an image, and you can see the metadata like the date it was taken, size, location, etc. The photo itself is the primary data, while the metadata provides supplementary information about the photo.\nDatabase It\u0026rsquo;s an organized collection of structured information, typically stored and accessed electronically from a computer system. It enables efficient storage, retrieval, and manipulation of data.\nThe classic example is to think of a library. Each book has its label with its title, author, etc. In the library, books are stored and organized, but instead of books, think of data. Like a filing system, a database helps to maintain structured information.\nStructured Data It refers to information that is organized in a specific format, making it easy to understand for both humans and computers. It consists of data elements organized in rows and columns, like a table.\nA phone directory contains structured data because it has specific fields organized such as name, phone number, address, and so on.\nUnstructured Data It refers to information that doesn\u0026rsquo;t have a specific format. Generally, unstructured data lacks a predefined structure, making it more challenging to analyze and process compared to structured data.\nImagine a stack of handwritten letters. Each letter may contain different types of information, such as personal stories, emotions, or opinions. These letters don\u0026rsquo;t follow a standardized format and can vary in length, writing style, or language.\nIn the digital world, emails, social media posts, images, videos, audio recordings, and free-text documents are examples of unstructured data.\nSemi-structured Data Semi-structured data falls between structured and unstructured data. It has some organization but doesn\u0026rsquo;t have a strict predefined format like structured data.\nThink of an email inbox. Each email consists of structured elements like sender, recipient, subject, and timestamp. However, the body of the email may contain unstructured information like free-text, attachments, or different formatting styles. This combination of structure and flexibility represents semi-structured data.\nData Testing It\u0026rsquo;s the process of examining and validating data to ensure its quality, accuracy, and reliability. It involves checking if the data meets expected standards and satisfies desired criteria. Essentially, data testing is like running tests on your data to detect errors or inconsistencies, ensuring that the information you\u0026rsquo;re working with is trustworthy and reliable.\nImagine you work as a cashier in a supermarket, and your job is to record the prices of different products sold. Data testing in this context would involve verifying that the price you enter for each product is correct, making sure there are no typos or mistakes. You could compare the entered prices with a reference list or check with a coworker to validate the accuracy of the recorded data.\nDuplicate Data It refers to having multiple identical or nearly identical copies of the same information within a dataset or systems.\nConsider the scenario where you\u0026rsquo;re managing your contact list. In that list, you store names, phone numbers, and emails of your friends. Now, let\u0026rsquo;s say you accidentally add the same contact twice, resulting in duplicated data.\nOrphaned Data They are data that exists without any associated or meaningful context. Essentially, these are data that lack proper connections or relationships with other data elements.\nThink of a library where you find a book missing information about its author, title, etc. This book becomes an orphaned book because it cannot be properly categorized or utilized, as it lacks the details that would make it valuable within the library system.\nSimilarly, in the context of data, orphaned data could be a data entry without any corresponding information, such as a customer record without a name or contact details. These data become difficult to analyze or use effectively because they lack the necessary context.\nIncomplete or Missing Data They are data that are not fully available or lack certain required information. This implies that there are gaps in the data that may hinder their usefulness for analysis or decision-making.\nImagine you\u0026rsquo;re traveling and using a navigation app (like Google Maps) that provides estimated travel times based on historical traffic data. However, if the app doesn\u0026rsquo;t have updated information about current traffic conditions or road closures, you won\u0026rsquo;t be able to accurately predict your travel time.\nIn this scenario, incomplete or missing data are the absence of real-time information about traffic. Similarly, in the world of data, missing data could occur when analyzing customer behavior if certain variables are not captured or recorded.\nMislabeled Data They are data that have been labeled or classified incorrectly, leading to inaccurate or misleading information. This implies that the data do not accurately represent their true nature or meaning.\nYou\u0026rsquo;re organizing a collection of photos. You have a folder called \u0026ldquo;Vacations in Hawaii,\u0026rdquo; but upon opening it, you find pictures from your vacations in Mexico. In the context of data, mislabeled data can occur when incorrect labels are assigned.\nData Swamp It\u0026rsquo;s the situation where a large amount of data becomes disorganized, unstructured, and difficult to use effectively. It\u0026rsquo;s a state where data lose value and become stagnant or unusable due to lack of proper management and organization.\nYou\u0026rsquo;re in a room filled with various objects like clothes, shoes, books, etc. The room is disorganized, and it becomes very difficult to find what you need. In this example, the cluttered room represents a data swamp.\nSimilarly, in the digital realm, a data swamp can arise when there\u0026rsquo;s an overwhelming amount of disorganized data stored across various systems, databases, or files.\nData Temperature It helps organizations more efficiently manage their data storage and retrieval strategies, ensuring that frequently accessed and critical data is available quickly while optimizing costs for less frequently accessed data.\nIn the realm of data, data temperature is generally classified into Hot Data, Warm Data, and Cold Data. \u0026ldquo;Hot\u0026rdquo; data refers to actively used and frequently accessed data (such as transactional data in a banking system), \u0026ldquo;warm\u0026rdquo; data refers to data accessed less frequently but still relevant for analysis or decision-making (such as historical sales data for analysis), and finally, \u0026ldquo;cold\u0026rdquo; data refers to data accessed rarely and considered less critical (such as data backups).\nData Lineage It\u0026rsquo;s the ability to track the origin and movement of data throughout its lifecycle. This helps you understand where data comes from, how it\u0026rsquo;s transformed, and where it goes, allowing you to track and analyze the flow of data within a system or organization. In simple terms, data lineage is like tracing the steps of your data, enabling you to understand its journey from start to finish and gain insight into how it\u0026rsquo;s used and transformed along the way.\nImagine you order a product online. The e-commerce platform processes your order, involving multiple steps such as inventory management, payment processing, and shipping. Data lineage in this scenario would involve tracking the journey of your order details from the moment you place the order until it arrives at your door. For example, data lineage could show that your order details originated in the online store\u0026rsquo;s database, then moved to the payment system, and subsequently to the logistics department for shipping.\nData Migration It\u0026rsquo;s the process of transferring data from one system, application, or storage location to another. It involves moving data from its current location to a new destination, ensuring its integrity, completeness, and compatibility. In summary, it\u0026rsquo;s like moving your digital data from one location to another, similar to moving physical objects from one house to another during a relocation.\nIt\u0026rsquo;s like moving from an old house to a new one. As part of the move, you need to transfer all your belongings, including furniture, appliances, and personal items from your old house to the new one. Data migration is similar to this process, but instead of physical objects, it involves moving digital data.\nDuring migration, it\u0026rsquo;s important to consider factors such as data format compatibility, data security, and data validation to ensure a successful transfer.\nData Model It\u0026rsquo;s the structured representation of data that defines how they are organized, stored, and related to each other. It describes the logical structure, relationships, and constraints of the data. A data model can be represented in various forms, such as a diagram, a schema, or a set of rules. Essentially, it\u0026rsquo;s the blueprint for designing and creating a data system.\nA popular way to represent a data model is through an Entity-Relationship (ER) diagram, where entities are represented with rectangles, and relationships are represented by lines connecting them.\nAnother way to represent the model is through a schema, which basically defines the structure and organization of a database. And lastly, a data model can also be defined using a set of rules that describe how the data can be organized and related (such as naming conventions, data integrity constraints, and data relationships).\nData Modeling It is the process of creating the data model. It involves analyzing requirements, understanding data sources, and designing the structure and relationships of the data. \u0026ldquo;Data Modeling\u0026rdquo; can be considered as the activity of translating concepts and entities from the real world into a formal representation of a data model.\nFor example, if you have an e-commerce platform, when creating a data model for such a platform, data modeling would involve identifying and representing key entities, relationships, and attributes. For instance, a user could represent a person who registers on the platform and may have attributes such as ID, name, contact information, and payment method details.\nData Maturity It\u0026rsquo;s a way of assessing where an organization stands in terms of how it uses and manages data. It represents the organization\u0026rsquo;s ability to collect, store, process, and analyze data effectively to gain valuable insights and make decisions.\nImagine you have a small business that relies on customer data to drive marketing campaigns. Initially, you gather customer information in spreadsheets and make decisions based on basic demographic data. At this stage, your maturity level is relatively low. As your business grows, you invest in a Customer Relationship Management (CRM) system that automates data collection and provides more advanced analytical capabilities.\nYou start using this data to create personalized marketing campaigns and track their effectiveness. At this stage, your maturity level would increase. Later on, you implement more sophisticated data management practices, such as data governance policies, data quality measurements, and data integration across multiple systems. You use Machine Learning algorithms to predict customer behavior and have a dedicated data team that continuously monitors and improves data processes. At this stage, your maturity level is high.\nData Pipeline It is a series of digital processes used to collect, modify, and deliver data from one place to another. It involves the ingestion of raw data from various sources, such as applications, devices, and other digital channels, and transferring them to a data repository, such as a Data Lake or Data Warehouse, for analysis.\nImagine you are on an online store. When you place an order, the website needs to process your order, check inventory, generate a shipping label, and send you a confirmation email. All these steps are part of a Data Pipeline because the website takes your order, goes through several stages, and finally, you receive your confirmation email.\nData Contract It\u0026rsquo;s a document that defines the structure, format, semantics, quality, and terms of use for data exchange between a data provider and its consumers. It helps ensure that data is consistent, reliable, and understandable across different systems.\nYou are a chef who needs ingredients from a supplier. In this case, a data contract would be a detailed shopping list that clearly specifies the type of ingredients, the quantity needed, etc.\nNow, in data, different systems need to share or exchange data. To ensure smooth communication, a contract helps define the structure and rules for the shared data. It specifies things like the data format (e.g., CSV, JSON), the fields and their types, any validation rules or constraints, and the expected behavior.\nData Entropy It describes the amount of uncertainty or disorder in a dataset. The higher the entropy, the greater the randomness and lack of patterns in the data.\nYou have a deck of cards that is perfectly ordered from ace to king in each suit. In this case, the data entropy is low because the order is predictable and does not contain much randomness. Now, consider a shuffled deck of cards where the cards are in a random order. In this case, the data entropy is high because the order is unpredictable and contains more randomness.\nData Debt It is the accumulation of problems arising from inadequate data management practices. Like technical debt, data debt results from neglecting the maintenance of data assets, leading to inconsistencies, redundancies, and inaccuracies in the data.\nImagine that in your company, stakeholders require a new data feature or product. Data scientists begin to explore and realize that the data is not available, so they ask the data engineers for a new data pipeline. However, the data engineers have multiple requests, so it will take them months to address this requirement.\nFeeling pressured, the data scientists decide not to wait and access source systems and databases directly without production standards or best practices. Consequently, they become accustomed to this process because it provides them with greater autonomy and end up creating a significant amount of data debt (thus generating data inconsistencies, high maintenance costs, or assigning blame to individuals for the data generated).\nData Silo It is a collection of data controlled by a department or business unit and isolated from the rest of the organization. Typically, the data ends up being stored in an independent system and often is incompatible with other datasets, making it difficult for users in other parts of the organization to access and use the data.\nImagine you have various puzzle pieces scattered across different rooms in your house. Each room represents a different department within a company, and the puzzle pieces represent data.\nIn the scenario of data silos, each department has its own puzzle piece separated from the others. The pieces in one room are not accessible or shared with other rooms. This means that each department has its own dataset that is isolated from the rest of the organization.\nData Management It is the process of collecting, storing, organizing, and using data securely, efficiently, and cost-effectively.\nYou have a large collection of family photos stored on your computer. To better manage your collection, you create folders and subfolders to categorize the photos based on events (probably separating folders by birthdays, vacations, etc.). If you want to find a particular photo, it is much easier to navigate to the corresponding folder instead of searching through the photos one by one.\nSimilarly, in data management, data must be organized, labeled, and stored in appropriate systems. This involves defining data structures, establishing naming conventions for data, determining access controls, and implementing data backup and recovery mechanisms.\nMaster Data Management It is a process and set of practices aimed at creating and managing a single \u0026lsquo;golden record\u0026rsquo; of important data entities within an organization to ensure coherence, accuracy, and reliability. MDM provides a unified view of data across various systems to meet business needs.\nYou are part of a retail company that operates multiple stores and an online platform. In this company, you have customer data scattered across different systems and databases (such as sales records, loyalty programs, and online registrations). Without adequate Master Data Management, you may end up with duplicate records or inconsistencies in the customer entity (for example, having Juan Hernandez in the sales system with different entries, loyalty program, and online registration system with different variations in name, contact information, etc.).\nSo the company decides to address this issue by creating an MDM. It decides to create a central repository that serves as the single source of truth for customer data. In this master data management system, data from different sources is consolidated, standardized, and duplicates are eliminated. Thus, instead of having multiple versions of Juan Hernandez records, the MDM ensures that there is only one consolidated and accurate record.\nData Democratization It means that everyone in the organization can access, understand, and use data to make decisions. To make data useful, organizations must break down data silos and ensure that various data users can collaborate, no longer relying on data specialists or IT departments.\nYou work for an e-commerce company that has a centralized analytics team responsible for generating reports and insights. Therefore, departments such as marketing, sales, and operations had to rely on the analytics team to request and interpret data for their decision-making processes.\nHowever, the company decides to implement data democratization. They introduce self-service analytics tools and dashboards that offer user-friendly interfaces for users to access and analyze data. Now, departments can easily navigate the analytics platform, run queries, and generate reports themselves without needing to involve the analytics team at every step.\nData Catalog It\u0026rsquo;s an organized inventory of data assets that uses metadata to help an organization manage its data. Think of it as a centralized repository where you can find relevant information for your data needs, as it helps you understand what data is available, where it\u0026rsquo;s located, and how you can access it.\nYou\u0026rsquo;re in a retail store. A data catalog would have information from various data sources, such as sales data, customer data, inventory data, and so on. It would include details like which dataset it contains, when it was last updated, who manages it, and relevant metadata.\nA data catalog encompasses a broader range of information about various data assets across the organization, including metadata, data lineage, data quality, and access information. The goal is to provide a comprehensive view of the organization\u0026rsquo;s data landscape.\nData Dictionary It focuses on providing definitions and descriptions of specific data elements within a database or dataset. It helps understand the meaning and format of individual data elements.\nYou have a contact management application and want to store information about your friends. For each friend, you want to save their name, phone number, and email address.\nA data dictionary would help provide an overview of available data, identify relevant resources, and allow you to see technical details such as schemas, data formats, responsible for maintenance, etc.\nData Ops It\u0026rsquo;s a practice that focuses on managing and optimizing the flow of data within an organization. It\u0026rsquo;s similar to how other processes are managed in a company, but it specifically focuses on data management. In summary, DataOps is a methodology used to manage and optimize the flow of data in an organization. It\u0026rsquo;s similar to DevOps but specifically focuses on data management.\nImagine you\u0026rsquo;re the manager of an online clothing store. You have a large amount of data, such as customer information, inventory, etc. To ensure that this data is useful and available when you need it, you need to implement DataOps.\nIn this case, DataOps would involve establishing processes and tools to efficiently collect, store, and analyze data. For example, you could use an automated system that automatically records customer data when they make a purchase, stores it in a secure database, and organizes it so you can easily access it.\nData Orchestration It involves the coordination and management of various data sources, processes, and workflows to ensure seamless integration and interaction. It includes activities such as data movement, transformation, scheduling, and monitoring to enable data-driven operations.\nYou are in charge of the supply chain management of a retail company. Data orchestration can be used to seamlessly coordinate inventory data from suppliers, sales data from stores, and shipping data to optimize the supply chain and ensure efficient operations. By orchestrating these data sources and processes, the company can make informed decisions and optimize its logistics.\nData Governance They are the policies, rules, and practices that ensure the quality, integrity, and security of data. It includes data cataloging, defining standards, and the process around how data is used in an organization.\nThink of the typical example where data governance is poorly executed or nonexistent. A business analyst has a requirement to create a report but doesn\u0026rsquo;t know which data to use to fulfill the request. They may spend hours scouring through dozens of tables in a transactional database, guessing which fields might be useful. The analyst creates a \u0026ldquo;correct\u0026rdquo; report but isn\u0026rsquo;t entirely sure if the data in the report is reliable. The recipient of the report also questions the validity of the data (not just of this report but also the data from the company\u0026rsquo;s systems). The company is confused about its reliability, making it difficult for planning and decision-making when using the data.\nData governance is fundamental for a company that wants to govern itself on data. When good data governance is practiced, people, processes, and technologies align to consider data as a key business driver. If issues arise with the data, they are addressed promptly. (Note: The main categories of data governance are observability, security, and accountability. Within these categories, there are subcategories such as data quality, metadata, and privacy.)\nData Owner It\u0026rsquo;s the individual or entity that has the responsibility and ultimate control over specific data assets. The data owner is usually responsible for determining who has access to the data, ensuring its accuracy and security, and defining its permitted use.\nAn example could be a hospital, where the chief physician or the hospital administrator may be designated as the data owners of patient medical records. They would be responsible for overseeing who can access the records, maintaining their confidentiality, and ensuring compliance with data protection regulations.\nData Steward Someone responsible for managing and ensuring the quality, security, and use of an organization\u0026rsquo;s data assets. They typically establish and enforce data management policies and procedures, oversee data integration, and facilitate compliance with regulations.\nYou are the manager of a financial institution overseeing the protection and privacy of customer data. You are responsible for ensuring that customer data is handled in accordance with legal requirements, industry standards, and internal policies, acting as a data steward for the organization\u0026rsquo;s sensitive financial data.\nData Guardian It refers to a role, policy, or specifically designated technology to protect the integrity, confidentiality, and availability of data. This could include permission management, implementation of security measures, and monitoring data access.\nImagine you\u0026rsquo;ve entrusted your house to a trusted neighbor while you\u0026rsquo;re on vacation. This neighbor watches over your house, waters your plants, and ensures no unwanted visitors enter. In this scenario, your house and belongings are your data, and the neighbor is the data guardian who keeps everything safe and in order until you return.\nIn a healthcare environment, a data guardian is crucial. They would oversee patient records, a type of sensitive data requiring rigorous protection. The guardian would ensure medical data is encrypted, access is logged and analyzed to detect unauthorized activities, and data is securely shared with authorized parties.\nData Security It refers to the protection of digital data against unauthorized access, corruption, or theft throughout its lifecycle. It involves implementing measures such as encryption, access controls, and monitoring to safeguard confidential information and prevent unauthorized breaches or disclosures.\nA financial institution encrypts customer financial data and implements strict access controls to prevent unauthorized individuals from viewing or modifying the data. This helps protect sensitive financial information from cyber threats and potential data breaches.\nData Privacy It consists of respecting individuals\u0026rsquo; rights and preferences regarding the use and handling of their personal data. It is the responsible management of individuals\u0026rsquo; personal information, ensuring that their data is protected against unauthorized access, use, or disclosure.\n\u0026ldquo;You don\u0026rsquo;t need privacy if you have nothing to hide\u0026rdquo; is a poor way to interpret privacy because it creates the sense that people demanding privacy must be criminals. We all know what happens when you go to the bathroom, but still, you close the door. An example of data privacy is when an online retailer collects customers\u0026rsquo; personal information to process orders, but ensures that this data is securely stored and obtains customers\u0026rsquo; consent for marketing communications.\nData Lifecycle It refers to the stages through which information passes from its initial creation or capture to its subsequent deletion or archiving. These stages typically include data creation, storage, use, sharing, archiving, and deletion.\nIt\u0026rsquo;s like the journey of a book: from when the author writes it, through its publication, reading by people, storage in a library, and possibly its archiving or withdrawal from circulation.\nIn the realm of data, an example of the data lifecycle would be the product information of a retail company. It begins with the creation of product information, then it\u0026rsquo;s stored in a database, used for online sales, shared with suppliers, archived for historical analysis, and finally deleted when the product is no longer available.\nData Engineering Lifecycle The data engineering cycle involves collecting, storing, processing, analyzing, and maintaining infrastructure. You detect sources, define storage, define ingestion, transform, and finally make information available.\nAn e-commerce company ingests data from multiple sources, transforms it, integrates it, conducts analysis, and visualizes the information to make better decisions. It\u0026rsquo;s an iterative process and involves continuously monitoring and improving.\nData Sources They refer to the origin or location from which data is collected or extracted for use in analysis, reporting, or decision-making.\nData sources can be compared to different ingredients used in cooking, such as fruits, vegetables, and spices, which are collected from various places to create a recipe.\nIn the realm of data, an example of data sources is a company that collects information from disparate systems, such as sales transactions from a point-of-sale system, customer data from a CRM platform, and web traffic data from an analytics tool, for business analysis and reporting.\nData Storage It\u0026rsquo;s a centralized place where data from multiple sources is collected and merged. It involves retaining data in a structured format for future access and use.\nIt\u0026rsquo;s like finding a place to store your books in a library so that you can later find and use them when needed. In the digital world, this concept involves using systems or devices to store and retrieve digital information.\nData Ingestion It\u0026rsquo;s the process of collecting, importing, and transferring data from various sources to a storage or computing system for subsequent processing and analysis.\nIt\u0026rsquo;s like gathering and organizing ingredients from different suppliers and bringing them to a restaurant\u0026rsquo;s kitchen to prepare meals.\nNow, in terms of data, an example would be a retail company that collects sales data from multiple stores and online channels, and ingests them into a centralized data warehouse for analysis and reporting.\nData Integration It focuses on combining data from different sources into a unified and consistent view. Its purpose is to establish a common data model.\nSimilarly to assembling puzzle pieces from different places to complete the picture, data integration unifies the sources. An example would be a company that merges customer data from a CRM, sales data from an ERP system, and marketing data from digital campaigns to create a comprehensive view for strategic business analysis and decision-making.\nData Transformation It\u0026rsquo;s like converting, reformatting, and restructuring data to adapt it for analysis, storage, or presentation.\nImagine you\u0026rsquo;re in a supermarket in a different country than the one you were born in, and you see prices in a different currency, so you have to compare prices and transform them into a currency that is easier for you to interpret.\nData Serving It\u0026rsquo;s the process of making data accessible and available to users or applications efficiently.\nThink of it like being in a restaurant and ordering a dish. The chefs in the kitchen prepare the food, and once it\u0026rsquo;s ready, the waiters serve the dish to your table. In the context of data, think of the data as the \u0026ldquo;food\u0026rdquo; and think of the users or applications as the \u0026ldquo;customers\u0026rdquo;.\nStaging Data It\u0026rsquo;s the process of temporarily storing and preparing data to load into a data warehouse, data lake, or other data repository.\nIt\u0026rsquo;s like preparing and organizing all the necessary tools, equipment, and materials before starting a home project, such as painting a room or assembling furniture. It involves having everything ready and organized to facilitate the smooth execution of the project.\nIn terms of data, it would involve storing and structuring raw data from various sources in a staging area before integrating it into a unified storage or analytics platform.\nData Warehouse It\u0026rsquo;s a centralized and optimized repository designed to handle large amounts of data from different sources. Its focus is on analysis and decision-making.\nYou\u0026rsquo;re the manager of several stores. You have sales data, inventory data, customer data, and other business-related data. It becomes complicated to obtain a comprehensive view of your business and make informed decisions based on scattered data. By creating a Data Warehouse, you consolidate and optimize the information for efficient queries, reporting, and analysis.\nData Mart It\u0026rsquo;s a subset of an organization\u0026rsquo;s data warehouse that is designed to serve a specific line of business or department.\nIt\u0026rsquo;s like a specialized section in a library that contains books, magazines, and resources focused on a specific topic or subject, meeting the needs of a particular group of readers.\nPutting it into the context of data, a practical example of a data mart is a sales department that has its own data mart within the company\u0026rsquo;s data warehouse, dedicated to storing and analyzing sales-related data for the department\u0026rsquo;s specific reporting and analysis requirements.\nData Lake It\u0026rsquo;s a repository that can collect a large amount of structured, semi-structured, and unstructured data that is stored until needed for processing or analysis.\nYou go on a trip to a beach and take several photos of where you\u0026rsquo;ve been. Instead of organizing your photos, you send them to your Photo Data Lake where they will be available in their original state. When you wish to categorize them, you can choose which photos and organize them according to your needs.\nData Lakehouse It\u0026rsquo;s a modern data management architecture that combines elements of a data lake and a data warehouse. A data lake ends up being a repository of raw data, while a data warehouse is highly structured and used for analytical purposes. A data lakehouse aims to store large amounts of structured and unstructured data (like a data lake) and supports the type of efficient data queries and analysis typically possible with a data warehouse.\nNetflix has to deal with a colossal volume of data from various sources, such as user data, preferences, streaming data, content metadata, etc. Traditionally, they could store raw data in a data lake and then process and move relevant parts to a data warehouse for analysis.\nWith a lakehouse, Netflix can store everything in one place, using advanced techniques in the same environment to perform complex analyses, recommend movies, understand viewing patterns, and optimize streaming quality without the need to constantly move data between a lake and a warehouse.\nData Platform It\u0026rsquo;s a technological infrastructure that enables the collection, storage, management, and analysis of data from various sources to support business operations and decision-making.\nA data platform resembles a central control panel that brings together various tools and systems, allowing users to access, manage, and analyze data effectively, like a single dashboard for multiple functions.\nA data platform streamlines the process of collecting, managing, and storing data, making it accessible and usable for various applications. It provides data management across the entire environment, including critical business functions such as security and observability. Without a data platform, each component is typically handled by a different tool or collection of tools to make data flow from the source to the end-user in a complex environment.\nData Mesh It\u0026rsquo;s a decentralized approach to data architecture that emphasizes the distribution of ownership, access, and data governance across different domains or business units within an organization.\nIn simple terms, Data Mesh resembles a network of autonomous local libraries, where each library manages and governs its collection independently, collaborating with others to provide a wide range of books and resources.\nA Data Mesh approach is an organization in which individual business units or departments manage and govern their own datasets, while also collaborating through shared standards and interfaces to enable the utilization and analysis of cross-functional data.\nData Sharing It\u0026rsquo;s the process of making the same data resources available to multiple applications, users, or organizations. It involves technologies, practices, legal frameworks, and cultural elements that facilitate secure access to data for multiple entities without compromising data integrity.\nData sharing improves efficiency within an organization and fosters collaboration with suppliers and partners. It enables stakeholders to learn from each other and collaborate on shared priorities.\nShared data can vary, from research articles or academic publications to corporate statistics, scientific data, or annual performance reviews.\nData Product It\u0026rsquo;s an application or software tool that uses data to provide valuable insights, services, or functionality to users or other systems.\nIt\u0026rsquo;s like a smartphone app that uses location data to provide personalized recommendations for nearby restaurants, helping users make informed decisions about where to dine.\nA data product is a business intelligence dashboard that integrates and visualizes sales, marketing, and financial data to provide actionable insights to decision-makers within an organization.\nData Quality It encompasses dimensions such as accuracy, completeness, consistency, reliability, and timeliness. It involves processes and technologies that measure, manage, and improve data health. Maintaining data quality requires vigilance in data management practices and continuous monitoring to detect and correct issues.\nThink of taking a road trip using a map. If the map is up-to-date, accurate, and detailed, you\u0026rsquo;re likely to have a smooth journey, but if it\u0026rsquo;s outdated, you might get lost or delayed. High-quality data is like an accurate and updated map for a business, leading to better decisions and more efficient operations.\nData Gathering It\u0026rsquo;s the process of gathering, compiling, and capturing information from various sources. Collection is essential for acquiring the necessary raw material for analysis, interpretation, and decision-making.\nAs simple as conducting a survey to gather information about customer preferences for a new product is an example of data collection. When someone conducts a survey, they can analyze responses to gather information about the needs and preferences of the respondents.\nData Engineer They\u0026rsquo;re the ones responsible for building and maintaining systems that collect, store, and process large amounts of data.\nIt\u0026rsquo;s like if you were to build and maintain roads for transportation. For example, if you worked at Amazon or Mercado Libre, you\u0026rsquo;d be responsible for delivering packages to their respective destinations and ensuring they\u0026rsquo;re properly packaged. A data engineer similarly ensures that data reaches its destination efficiently.\nData Analyst They are responsible for exploring and finding patterns to gain knowledge of the domain in question. They use statistics and necessary tools to understand the past and the present.\nIf you were a detective, analyzing data would help you turn clues into a logical story. You take numbers and facts and transform them into information to understand what happened and what is happening.\nData Scientist It\u0026rsquo;s similar to a data analyst, but the difference is that data scientists use robust statistical techniques and machine learning to predict the future. (Analysts deal with the past and present, scientists focus on the future.)\nIf you want to predict the weather, you first need to understand why some regions receive more rain than others, then collect data on temperature, patterns, etc. Next, you use tools to analyze and predict when it will rain, or you use tools to make decisions to see if it\u0026rsquo;s safe to travel.\nData Architect Designs the overall structure for how data is stored, organized, and used within an organization. They decide which technologies will be used to manage the data and create rules and policies to ensure data quality and reliability. Their role also involves ensuring that data systems are flexible and can adapt to the changing needs of the business.\nConsider the analogy of building a house. Just as you need a blueprint to determine where doors, the kitchen, and rooms will go, a data architect establishes how data is stored and connected within an organization.\nSo, a data architect is like the blueprint creator for a company\u0026rsquo;s data infrastructure, ensuring that everything is properly organized and interconnected to support the organization\u0026rsquo;s needs.\n","permalink":"https://thedatafixer.xyz/datafordummies/","summary":"If you\u0026rsquo;ve ever felt overwhelmed by terms like Data Lake, metadata, or Data Governance, then you\u0026rsquo;ve come to the right place. I know that even for the same concept, there can be different interpretations, so my intention is not to define but to explain the word in a simple way, accompanied by an example or context.\nIf you think something should be added or edited, you can leave a comment at the end of this post, or you can also contact me in whichever way is most convenient for you.","title":"Data for Dummies"}]